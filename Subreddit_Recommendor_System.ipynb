{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit recommender system in Python\n",
    "Nowadays, **recommender systems** are used to personalize your experience on the web, telling you what to buy, where to eat or even who you should be friends with. People's tastes vary, but generally follow patterns. People tend to like things that are similar to other things they like, and they tend to have similar taste as other people they are close with. Recommender systems try to capture these patterns to help predict what else you might like.\n",
    "\n",
    "<img src='http://etailment.de/news/media/1/humor-e-commerce-5672-detailp.jpeg'/>\n",
    "\n",
    "\n",
    "#### I will be using the subreddit interaction dataset.\n",
    "\n",
    "<img src='https://assets.ifttt.com/images/channels/1352860597/icons/on_color_large.png'/>\n",
    "\n",
    "It contains subreddit interactions from approximately 25k users.You should add unzipped subreddit dataset folder to your notebook directory.You can download the dataset [here](https://www.kaggle.com/colemaclean/subreddit-interactions/downloads/subreddit-interactions-for-25000-users.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import csv\n",
    "from pandas import DataFrame,Series,read_csv\n",
    "import scipy.sparse as sp\n",
    "from sparsesvd import sparsesvd        #used for matrix factorization\n",
    "from scipy.sparse import csc_matrix    #used for sparse matrix\n",
    "from scipy.sparse.linalg import *      #used for matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a sneak peek of the first 5 rows in the dataset. Next, let's count the number of unique users and subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows of the dataset - \n",
      "    username         subreddit           utc\n",
      "0  kabanossi  photoshopbattles  1.482748e+09\n",
      "1  kabanossi      GetMotivated  1.482748e+09\n",
      "2  kabanossi            vmware  1.482748e+09\n",
      "3  kabanossi           carporn  1.482748e+09\n",
      "4  kabanossi               DIY  1.482747e+09\n"
     ]
    }
   ],
   "source": [
    "subreddit_df = read_csv('reddit_data.csv')\n",
    "print \"Top 5 rows of the dataset - \\n\"+ str(subreddit_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 22610\n",
      "Number of subreddits = 34967\n"
     ]
    }
   ],
   "source": [
    "n_users = subreddit_df.username.unique().shape[0]\n",
    "n_items = subreddit_df.subreddit.unique().shape[0]\n",
    "print 'Number of users = ' + str(n_users) + '\\nNumber of subreddits = ' + str(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset = 14000000\n",
      "Number of columns = 3\n"
     ]
    }
   ],
   "source": [
    "print \"Number of rows in the dataset = \" +str(subreddit_df.shape[0])+ \\\n",
    "'\\nNumber of columns = ' + str(subreddit_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering some information from the data and checking if it contains Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information from the data set - \n",
      " \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14000000 entries, 0 to 13999999\n",
      "Data columns (total 3 columns):\n",
      "username     object\n",
      "subreddit    object\n",
      "utc          float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 320.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print \"Information from the data set - \\n \"\n",
    "subreddit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null entries in the Dataset - \n",
      "username     False\n",
      "subreddit    False\n",
      "utc          False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print \"Number of Null entries in the Dataset - \\n\" + str(subreddit_df.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets list down the most popular subreddits based on the user interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>065_082_071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x10c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x3642</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit  subreddit_count\n",
       "0          007                3\n",
       "1  065_082_071                1\n",
       "2          0ad                4\n",
       "3        0x10c                3\n",
       "4       0x3642               39"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_grouped = subreddit_df.groupby(['subreddit']).agg({'username': 'count'}).\\\n",
    "                    rename(columns={'username':'subreddit_count'}).reset_index()\n",
    "subreddit_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000000L"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_sum = subreddit_grouped['subreddit_count'].sum()\n",
    "grouped_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1030290</td>\n",
       "      <td>7.359214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29812</th>\n",
       "      <td>politics</td>\n",
       "      <td>367860</td>\n",
       "      <td>2.627571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17058</th>\n",
       "      <td>The_Donald</td>\n",
       "      <td>216939</td>\n",
       "      <td>1.549564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28536</th>\n",
       "      <td>nfl</td>\n",
       "      <td>173883</td>\n",
       "      <td>1.242021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26783</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>157663</td>\n",
       "      <td>1.126164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34646</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>156605</td>\n",
       "      <td>1.118607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24419</th>\n",
       "      <td>funny</td>\n",
       "      <td>152921</td>\n",
       "      <td>1.092293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28380</th>\n",
       "      <td>nba</td>\n",
       "      <td>150985</td>\n",
       "      <td>1.078464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29564</th>\n",
       "      <td>pics</td>\n",
       "      <td>143496</td>\n",
       "      <td>1.024971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28497</th>\n",
       "      <td>news</td>\n",
       "      <td>140492</td>\n",
       "      <td>1.003514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit  subreddit_count  percentage\n",
       "1402         AskReddit          1030290    7.359214\n",
       "29812         politics           367860    2.627571\n",
       "17058       The_Donald           216939    1.549564\n",
       "28536              nfl           173883    1.242021\n",
       "26783  leagueoflegends           157663    1.126164\n",
       "34646        worldnews           156605    1.118607\n",
       "24419            funny           152921    1.092293\n",
       "28380              nba           150985    1.078464\n",
       "29564             pics           143496    1.024971\n",
       "28497             news           140492    1.003514"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_grouped['percentage']  = subreddit_grouped['subreddit_count'].div(grouped_sum)*100\n",
    "subreddit_grouped.sort_values(['subreddit_count', 'subreddit'], ascending = [0,1]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above table clearly shows the top 10 reddits based on the user interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data to convert into User - Subreddit Matrix Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>AOImmortals</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Addons4Kodi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Assistance</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>FantasyPL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>FiftyFifty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username      subreddit  subreddit_count\n",
       "0  --ANUSTART-    AOImmortals                2\n",
       "1  --ANUSTART-    Addons4Kodi                1\n",
       "2  --ANUSTART-  AdviceAnimals                7\n",
       "3  --ANUSTART-      AskReddit               14\n",
       "4  --ANUSTART-     Assistance                9\n",
       "5  --ANUSTART-  CombatFootage                1\n",
       "6  --ANUSTART-  Documentaries                1\n",
       "7  --ANUSTART-      FantasyPL                3\n",
       "8  --ANUSTART-     FiftyFifty                1\n",
       "9  --ANUSTART-        Fitness                7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_sub_df = subreddit_df.groupby(['username','subreddit']).agg({'subreddit':'count'}).\\\n",
    "              rename(columns={'subreddit':'subreddit_count'}).reset_index()\n",
    "user_sub_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets convert the subreddit count into a subreddit document format which will be helpful while converting into a matrix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_sub_doc_df = subreddit_df.groupby('username')['subreddit'].apply(lambda x: \"%s\" % ' '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Testosterone Testosterone Testosterone Testost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--Sko--</td>\n",
       "      <td>DestinyTheGame DestinyTheGame DestinyTheGame D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--UNKN0WN--</td>\n",
       "      <td>AceAttorney AceAttorney AceAttorney AceAttorne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--harley--quinn--</td>\n",
       "      <td>LGBTeens Patriots asktransgender Patriots Patr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-A-p-r-i-l-</td>\n",
       "      <td>tdi tdi tdi AskReddit tdi tdi tdi tdi tdi tdi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            username                                          subreddit\n",
       "0        --ANUSTART-  Testosterone Testosterone Testosterone Testost...\n",
       "1            --Sko--  DestinyTheGame DestinyTheGame DestinyTheGame D...\n",
       "2        --UNKN0WN--  AceAttorney AceAttorney AceAttorney AceAttorne...\n",
       "3  --harley--quinn--  LGBTeens Patriots asktransgender Patriots Patr...\n",
       "4        -A-p-r-i-l-  tdi tdi tdi AskReddit tdi tdi tdi tdi tdi tdi ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_sub_doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Testosterone, Testosterone, Testosterone, Tes...\n",
       "1    [DestinyTheGame, DestinyTheGame, DestinyTheGam...\n",
       "2    [AceAttorney, AceAttorney, AceAttorney, AceAtt...\n",
       "3    [LGBTeens, Patriots, asktransgender, Patriots,...\n",
       "4    [tdi, tdi, tdi, AskReddit, tdi, tdi, tdi, tdi,...\n",
       "Name: subreddit, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "document = user_sub_doc_df.iloc[:, 1]\n",
    "document = document.apply(lambda row: tokenizer.tokenize(row))\n",
    "document.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique users -  22610\n",
      "The number of unique subreddits -  34967\n"
     ]
    }
   ],
   "source": [
    "user_queries = subreddit_df['subreddit'].unique()\n",
    "users = user_sub_doc_df['username'].unique()\n",
    "print \"The number of unique users - \",str(len(users))\n",
    "print \"The number of unique subreddits - \",str(len(user_queries))\n",
    "corpus_of_subreddits = []\n",
    "for unique_subreddit in user_queries:\n",
    "    corpus_of_subreddits.append(unique_subreddit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets create User Vs Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of user subreddit matrix are - (22610, 34967)\n"
     ]
    }
   ],
   "source": [
    "voc2id = dict(zip(corpus_of_subreddits, range(len(corpus_of_subreddits))))\n",
    "rows, cols, vals = [], [], []\n",
    "for r, d in enumerate(document):\n",
    "    for e in d:\n",
    "        if voc2id.get(e) is not None:\n",
    "            rows.append(r)\n",
    "            cols.append(voc2id[e])\n",
    "            vals.append(1)\n",
    "user_subreddit_matrix = csc_matrix((vals, (rows, cols)), dtype=np.float32)\n",
    "print \"The dimensions of user subreddit matrix are - \" +str(user_subreddit_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets calculate the sparsity of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of Subreddit dataframe is 98.2%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(subreddit_df)/float(len(users)*len(user_queries)),3)\n",
    "print 'The sparsity level of Subreddit dataframe is ' +  str(sparsity*100) + '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "A well-known matrix factorization method is **Singular value decomposition (SVD)**. Collaborative Filtering can be formulated by approximating a matrix `X` by using singular value decomposition. The winning team at the Netflix Prize competition used SVD matrix factorization models to produce product recommendations, for more information I recommend to read articles: [Netflix Recommendations: Beyond the 5 stars](http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html) and [Netflix Prize and SVD](http://buzzard.ups.edu/courses/2014spring/420projects/math420-UPS-spring-2014-gower-netflix-SVD.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets define a function which converts the user subreddit matrix into corresponding svd matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeSVD(user_subreddit_matrix, no_of_latent_factors):\n",
    "    \n",
    "    \"\"\"Compute the SVD of the given matrix.\n",
    "    :user_subreddit_matrix: a numeric matrix\n",
    "    :no_of_latent_factors : numeric scalar value\n",
    "    \n",
    "    :U  : User to concept matrix \n",
    "    :S  : Strength of the concepts matrix\n",
    "    :Vt : Subreddit to concept matrix\n",
    "    \"\"\"\n",
    "    U, s, Vt = sparsesvd(user_subreddit_matrix, no_of_latent_factors)\n",
    "    \n",
    "    dim = (len(s), len(s))\n",
    "    S = np.zeros(dim, dtype=np.float32)\n",
    "    for i in range(0, len(s)):\n",
    "        S[i,i] = mt.sqrt(s[i])\n",
    "\n",
    "    U = csc_matrix(np.transpose(U), dtype=np.float32)\n",
    "    S = csc_matrix(S, dtype=np.float32)\n",
    "    Vt = csc_matrix(Vt, dtype=np.float32)\n",
    "\n",
    "    return U, S, Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute estimated recommendations for the given user\n",
    "def computeEstimatedRecommendation(U, S, Vt, uTest):\n",
    "    \"\"\"Compute the recommendation for the given user.\n",
    "    \n",
    "    :U     : User to concept matrix \n",
    "    :S     : Strength of the concepts matrix\n",
    "    :Vt    : Subreddit to concept matrix\n",
    "    :uTest : Index of the user for which the recommendation has to be made\n",
    "    \n",
    "    :recom : List of recommendations made to the user\n",
    "    \"\"\"\n",
    " \n",
    "    #constants defining the dimensions of the estimated rating matrix\n",
    "    MAX_PID = 34967\n",
    "    MAX_UID = 22610\n",
    "    \n",
    "    rightTerm = S*Vt \n",
    "\n",
    "    EstimatedRecommendation = np.zeros(shape=(MAX_UID, MAX_PID), dtype=np.float16)\n",
    "    for userTest in uTest:\n",
    "        prod = U[userTest, :]*rightTerm\n",
    "        # Converting the vector to dense format in order to get the indices \n",
    "        # of the movies with the best estimated ratings \n",
    "        \n",
    "        EstimatedRecommendation[userTest, :] = prod.todense()\n",
    "        recom = (-EstimatedRecommendation[userTest, :]).argsort()[:250]\n",
    "    return recom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the contribution of the top 250 subreddits to decide the number of latent factors for SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 250 subreddits contribute a total of 61.8459428571 percentage to the total subreddits in the dataset\n"
     ]
    }
   ],
   "source": [
    "subreddit_contributions = subreddit_grouped.sort_values(['subreddit_count', 'subreddit'],\\\n",
    "                                                        ascending = [0,1]).head(250)\n",
    "\n",
    "print \"Top 250 subreddits contribute a total of %s percentage to the total subreddits in the dataset\"\\\n",
    "      %sum(subreddit_contributions.percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_of_latent_factors = 250 #Selected number of latent factors as 250\n",
    "no_of_recommendations_for_each_user = 5\n",
    "uTest = [np.where(users == 'kabanossi')[0][0]]\n",
    "U, S, Vt = computeSVD(user_subreddit_matrix, no_of_latent_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "User for whom recommendations are needed: kabanossi\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Previous Subreddit interactions - \n",
      "\n",
      "photoshopbattles\n",
      "GetMotivated\n",
      "vmware\n",
      "carporn\n",
      "DIY\n",
      "food\n",
      "CatastrophicFailure\n",
      "techsupport\n",
      "VapePorn\n",
      "nottheonion\n",
      "Citrix\n",
      "sysadmin\n",
      "HyperV\n",
      "Vaping\n",
      "wheredidthesodago\n",
      "networking\n",
      "HOTandTRENDING\n",
      "creepy\n",
      "Catloaf\n",
      "CozyPlaces\n",
      "MechanicalKeyboards\n",
      "freenas\n",
      "Justrolledintotheshop\n",
      "trippinthroughtime\n",
      "nevertellmetheodds\n",
      "homelab\n",
      "oddlysatisfying\n",
      "AnimalsBeingJerks\n",
      "pcmasterrace\n",
      "Technology_\n",
      "techsupportmacgyver\n",
      "techsupportgore\n",
      "OSHA\n",
      "GifRecipes\n",
      "europe\n",
      "interestingasfuck\n",
      "funny\n",
      "sports\n",
      "synology\n",
      "AskEngineers\n",
      "mallninjashit\n",
      "knitting\n",
      "philadelphia\n",
      "tattoos\n",
      "EarthPorn\n",
      "gaming\n",
      "AnimalsBeingBros\n",
      "pics\n",
      "gifs\n",
      "OldSchoolCool\n",
      "mildlyinteresting\n",
      "WTF\n",
      "HomeNetworking\n",
      "DataHoarder\n",
      "battlefield_one\n",
      "virtualization\n",
      "RealGirls\n",
      "cats\n",
      "titanfall\n",
      "DestinyTheGame\n",
      "news\n",
      "aww\n",
      "Showerthoughts\n",
      "natureismetal\n",
      "thalassophobia\n",
      "Art\n",
      "Sierra_Skye\n",
      "CabinPorn\n",
      "houston\n",
      "MostBeautiful\n",
      "CrappyDesign\n",
      "AskReddit\n",
      "BuyItForLife\n",
      "trees\n",
      "talesfromtechsupport\n",
      "reallifedoodles\n",
      "technology\n",
      "pokemongo\n",
      "DAE\n",
      "SydneySierota\n",
      "hiphopheads\n",
      "BMW\n",
      "k12sysadmin\n",
      "conservativecartoons\n",
      "pittsburgh\n",
      "Badfaketexts\n",
      "ImagesOfCalifornia\n",
      "itsaunixsystem\n",
      "battlestations\n",
      "space\n",
      "personalfinance\n",
      "buildapc\n",
      "macrumorsofficial\n",
      "worldpolitics\n",
      "Mafia3\n",
      "woodworking\n",
      "DeepIntoYouTube\n",
      "ArtefactPorn\n",
      "knives\n",
      "dataisbeautiful\n",
      "Sneakers\n",
      "worldbuilding\n",
      "keming\n",
      "The_Donald\n",
      "russiawarinukraine\n",
      "japan\n",
      "science\n",
      "Astronomy\n",
      "nonononoyes\n",
      "GunsAreCool\n",
      "spotted\n",
      "ChicksWithGuns\n",
      "4x4\n",
      "YanetGarcia\n",
      "Watches\n",
      "urbanexploration\n",
      "subaru\n",
      "gifsthatkeepongiving\n",
      "TheWayWeWere\n",
      "funhaus\n",
      "eatsandwiches\n",
      "2007scape\n",
      "hitmanimals\n",
      "DNCleaks\n",
      "BlackPeopleTwitter\n",
      "UNBGBBIIVCHIDCTIICBG\n",
      "PerfectTiming\n",
      "guns\n",
      "AdviceAnimals\n",
      "holdmybeer\n",
      "fo4\n",
      "mechanical_gifs\n",
      "Fishing\n",
      "australia\n",
      "Veeam\n",
      "Bitcoin\n",
      "circlejerk\n",
      "balisong\n",
      "coding\n",
      "NoFap\n",
      "worldnews\n",
      "NoMansSkyTheGame\n",
      "waze\n",
      "motorcycles\n",
      "relationships\n",
      "FreeEuropeNews\n",
      "britishproblems\n",
      "reactiongifs\n",
      "LifeProTips\n",
      "NoStupidQuestions\n",
      "ImagesOfNewYork\n",
      "instant_regret\n",
      "unitedkingdom\n",
      "Shitty_Car_Mods\n",
      "retrogaming\n",
      "gadgets\n",
      "multiwall\n",
      "abandonware\n",
      "computertechs\n",
      "linuxadmin\n",
      "WEPES\n",
      "sports_undelete\n",
      "linuxmint\n",
      "windows\n",
      "RX200\n",
      "ironmaiden\n",
      "TechNewsToday\n",
      "woahdude\n",
      "Sysadminhumor\n",
      "24hoursupport\n",
      "MildlyVandalised\n",
      "cthulhumod\n",
      "storage\n",
      "smashbros\n",
      "Futurology\n",
      "WelshFootball\n",
      "ShouldIbuythisgame\n",
      "soccer\n",
      "xboxone\n",
      "systemofadown\n",
      "SuggestALaptop\n",
      "psg\n",
      "photography\n",
      "CapeCod\n",
      "PES2016\n",
      "Fantasy\n",
      "Metalcore\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"User for whom recommendations are needed: %s\\n\" % users[uTest[0]])\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"Previous Subreddit interactions - \\n\")\n",
    "previous_subredit_history = user_queries[np.where(user_subreddit_matrix[uTest[0],:].todense().T != 0)[0]]\n",
    "previous_subredit_history\n",
    "for previous_subredits in previous_subredit_history:\n",
    "     print previous_subredits\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Recommendation for kabanossi are as follows - \n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "apple\n",
      "hardwareswap\n",
      "vancouver\n",
      "programming\n",
      "elderscrollsonline\n",
      "------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get estimated recommendations for test user\n",
    "recommended_items = computeEstimatedRecommendation(U, S, Vt, uTest)\n",
    "final_recommendation = []\n",
    "for r in user_queries[recommended_items]:\n",
    "    if r not in previous_subredit_history:\n",
    "        final_recommendation.append(r)\n",
    "        if len(final_recommendation) == no_of_recommendations_for_each_user:\n",
    "            break\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"Recommendation for %s are as follows - \\n\" % users[uTest[0]])\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "for recommendation in final_recommendation:\n",
    "    print recommendation\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
